{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Predicción 1 paso adelante usando 2 retardos\n",
        "warning: false\n",
        "code-fold: true\n",
        "---"
      ],
      "id": "ed530ae4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a importar la bases de datos y a convertirlas en objetos de series de Tiempo. $\\{X_t\\}$\n"
      ],
      "id": "fd4c71e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get working directory\n",
        "import os\n",
        "os.getcwd()"
      ],
      "id": "30e1dd71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import sklearn\n",
        "import openpyxl\n",
        "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
        "import warnings\n",
        "print(f\"Matplotlib Version: {plt.__version__}\")\n",
        "print(f\"Pandas Version: {pd.__version__}\")\n",
        "print(f\"Numpy Version: {np.__version__}\")\n",
        "print(f\"Sklearn: {sklearn.__version__}\")"
      ],
      "id": "071d8ea9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lectura de la serie\n",
        "data = pd.read_excel(\"datos/Exportaciones.xlsx\",\n",
        "                   header = 0, usecols = ['Mes','Total']).iloc[96:].reset_index(drop = True).round()\n",
        "data['Total'] = data['Total'].astype(int) \n",
        "data"
      ],
      "id": "97e890e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# tipo de datos\n",
        "print(data.info())"
      ],
      "id": "bba1c032",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#mirando los datos\n",
        "#objeto ts\n",
        "exportaciones = data['Total']\n",
        "print(type(exportaciones))\n",
        "plt.plot(exportaciones)"
      ],
      "id": "0119c8af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f'Numero de filas con valores faltantes: {data.isnull().any(axis=1).mean()}')"
      ],
      "id": "3bf54c0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.shape"
      ],
      "id": "74e858e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PACF\n",
        "\n",
        "usaremos la funcion de autocorrealcion parcial para darnos una idea de cuantos rezagos usaremos en el modelo\n"
      ],
      "id": "9c1b8838"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from matplotlib import pyplot\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "plot_pacf(exportaciones,lags=140,method='ywm',alpha=0.01)\n",
        "pyplot.show()"
      ],
      "id": "9ee7e93b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "pacf =  sm.tsa.stattools.pacf(exportaciones, nlags=140,method='ywm')\n",
        "T = len(exportaciones)\n",
        "\n",
        "sig_test = lambda tau_h: np.abs(tau_h) > 2.58/np.sqrt(T)"
      ],
      "id": "19537228",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pacf"
      ],
      "id": "6d2ef09c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(len(pacf)):\n",
        "    if sig_test(pacf[i]) == False:\n",
        "        n_steps = i - 1\n",
        "        print('n_steps set to', n_steps)\n",
        "        break"
      ],
      "id": "643932de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que con el **pacf** se nos recomienda usar dos retardos, lo cuál nos recueda que cuando se quizo establecer una componente estacional se sugeria un periodo de 2.4, por lo tanto teniendo encuenta lo anterior usaremos **2 retrasos** para la serie original\n",
        "\n",
        "# Árboles de decisión\n",
        "\n",
        "### Creación de los rezagos\n",
        "\n",
        "Debido al análisis previo tomaremos los rezagos de 2 días atrás para poder predecir un paso adelante.\n"
      ],
      "id": "9401b79e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas import DataFrame\n",
        "# reframe as supervised learning\n",
        "# lag observation (t-1) is the input variable and t is the output variable.\n",
        "df1 = DataFrame() # original\n",
        "print(df1)\n",
        "df2 = DataFrame() #diferenciada\n",
        "print(df2)"
      ],
      "id": "3558ef05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# arreglo de datos para el arreglo de rezagos Serie Original\n",
        "indice = pd.date_range(start='1/1/2000', periods=282, freq='M')\n",
        "print(indice)\n",
        "originalDatadf = pd.DataFrame(data['Total'].values,index=indice)\n",
        "print(originalDatadf)"
      ],
      "id": "6e48ea75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Rezagos original\n",
        "for i in range(2,0,-1):\n",
        "    df1[['t-'+str(i)]] = originalDatadf.shift(i)\n",
        "print(df1)"
      ],
      "id": "96b3a3c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create column t original\n",
        "df1['t'] = originalDatadf.values\n",
        "print(df1.head(14))"
      ],
      "id": "e5ab5d50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a new subsetted dataframe, removing Nans from first 3 rows original\n",
        "df1_Ori = df1[2:]\n",
        "print(df1_Ori)\n",
        "df1_Ori.size"
      ],
      "id": "c1f33d5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split data Serie Original\n",
        "Orig_Split = df1_Ori.values\n",
        "# split into lagged variables and original time series\n",
        "X1 = Orig_Split[:, 0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
        "y1 = Orig_Split[:,-1]  # slice all rows and last column, essentially separating out 't' column\n",
        "print(X1)\n",
        "print('Respuestas \\n',y1)"
      ],
      "id": "8f8ac4bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Árbol para Serie Original\n",
        "\n",
        "#### Entrenamiento, Validación y prueba\n"
      ],
      "id": "f1c3089e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Y1 = y1\n",
        "print('Complete Observations for Target after Supervised configuration: %d' %len(Y1))\n",
        "traintarget_size = int(len(Y1) * 0.70) \n",
        "valtarget_size = int(len(Y1) * 0.10)+1# Set split\n",
        "testtarget_size = int(len(Y1) * 0.20)# Set split\n",
        "print(traintarget_size,valtarget_size,testtarget_size)\n",
        "print('Train + Validation + Test: %d' %(traintarget_size+valtarget_size+testtarget_size))"
      ],
      "id": "c61bc0b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Target Train-Validation-Test split(70-10-20)\n",
        "train_target, val_target,test_target = Y1[0:traintarget_size], Y1[(traintarget_size):(traintarget_size+valtarget_size)],Y1[(traintarget_size+valtarget_size):len(Y1)]\n",
        "\n",
        "print('Observations for Target: %d' % (len(Y1)))\n",
        "print('Training Observations for Target: %d' % (len(train_target)))\n",
        "print('Validation Observations for Target: %d' % (len(val_target)))\n",
        "print('Test Observations for Target: %d' % (len(test_target)))"
      ],
      "id": "0c42c491",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Features Train--Val-Test split\n",
        "\n",
        "trainfeature_size = int(len(X1) * 0.70)\n",
        "valfeature_size = int(len(X1) * 0.10)+1# Set split\n",
        "testfeature_size = int(len(X1) * 0.20)# Set split\n",
        "train_feature, val_feature,test_feature = X1[0:traintarget_size],X1[(traintarget_size):(traintarget_size+valtarget_size)] ,X1[(traintarget_size+valtarget_size):len(Y1)]\n",
        "\n",
        "print('Observations for Feature: %d' % (len(X1)))\n",
        "print('Training Observations for Feature: %d' % (len(train_feature)))\n",
        "print('Validation Observations for Feature: %d' % (len(val_feature)))\n",
        "print('Test Observations for Feature: %d' % (len(test_feature)))"
      ],
      "id": "99241732",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Árbol\n"
      ],
      "id": "d0a665ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decision Tree Regresion Model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Create a decision tree regression model with default arguments\n",
        "decision_tree_Orig = DecisionTreeRegressor()  # max-depth not set\n",
        "# The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "# Fit the model to the training features(covariables) and targets(respuestas)\n",
        "decision_tree_Orig.fit(train_feature, train_target)\n",
        "# Check the score on train and test\n",
        "print(\"Coeficiente R2 sobre el conjunto de entrenamiento:\",decision_tree_Orig.score(train_feature, train_target))\n",
        "print(\"Coeficiente R2 sobre el conjunto de Validación:\",decision_tree_Orig.score(val_feature,val_target))  # predictions are horrible if negative value, no relationship if 0\n",
        "print(\"el RECM sobre validación es:\",(((decision_tree_Orig.predict(val_feature)-val_target)**2).mean()) )"
      ],
      "id": "18f8dbfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que el R2 para los datos de validación es bueno así sin ningún ajuste, Se relizara un ajuste de la profundidad como hiperparametro para ver si mejora dicho valor\n"
      ],
      "id": "a8f96e5d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find the best Max Depth\n",
        "\n",
        "# Loop through a few different max depths and check the performance\n",
        "# Try different max depths. We want to optimize our ML models to make the best predictions possible.\n",
        "# For regular decision trees, max_depth, which is a hyperparameter, limits the number of splits in a tree.\n",
        "# You can find the best value of max_depth based on the R-squared score of the model on the test set.\n",
        "\n",
        "for d in [2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15]:\n",
        "    # Create the tree and fit it\n",
        "    decision_tree_Orig = DecisionTreeRegressor(max_depth=d)\n",
        "    decision_tree_Orig.fit(train_feature, train_target)\n",
        "    \n",
        "    # Print out the scores on train and test\n",
        "    print('max_depth=', str(d))\n",
        "    print(\"Coeficiente R2 sobre el conjunto de entrenamiento:\",decision_tree_Orig.score(train_feature, train_target))\n",
        "    print(\"Coeficiente R2 sobre el conjunto de validación:\",decision_tree_Orig.score(val_feature, val_target), '\\n')  # You want the test score to be positive and high\n",
        "    print(\"el RECM sobre el conjunto de validación es:\",sklearn.metrics.mean_squared_error(decision_tree_Orig.predict(val_feature),val_target, squared=False))"
      ],
      "id": "702a1816",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note que los scores para el conjunto de validación son negativos para todas las profundidades evaluadas. Ahora uniremos validacion y entrenamiento para re para reestimar los parametros\n"
      ],
      "id": "f55e078b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(train_feature))\n",
        "print(type(val_feature))\n",
        "#######\n",
        "print(type(train_target))\n",
        "print(type(val_target))\n",
        "####\n",
        "print(train_feature.shape)\n",
        "print(val_feature.shape)\n",
        "#####\n",
        "####\n",
        "print(train_target.shape)\n",
        "print(val_target.shape)\n",
        "###Concatenate Validation and test\n",
        "train_val_feature=np.concatenate((train_feature,val_feature),axis=0)\n",
        "train_val_target=np.concatenate((train_target,val_target),axis=0)\n",
        "print(train_val_feature.shape)\n",
        "print(train_val_target.shape)"
      ],
      "id": "90d6d31a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use the best max_depth \n",
        "decision_tree_Orig = DecisionTreeRegressor(max_depth=4)  # fill in best max depth here\n",
        "decision_tree_Orig.fit(train_val_feature, train_val_target)\n",
        "\n",
        "# Predict values for train and test\n",
        "train_val_prediction = decision_tree_Orig.predict(train_val_feature)\n",
        "test_prediction = decision_tree_Orig.predict(test_feature)\n",
        "\n",
        "# Scatter the predictions vs actual values\n",
        "plt.scatter(train_val_prediction, train_val_target, label='train')  # blue\n",
        "plt.scatter(test_prediction, test_target, label='test')  # orange\n",
        "# Agrega títulos a los ejes\n",
        "plt.xlabel('Valores Predichos')  # Título para el eje x\n",
        "plt.ylabel('Valores Objetivo')  # Título para el eje y\n",
        "# Muestra una leyenda\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"Raíz de la Pérdida cuadrática Entrenamiento:\",sklearn.metrics.mean_squared_error( train_val_prediction, train_val_target,squared=False))\n",
        "\n",
        "print(\"Raíz de la Pérdida cuadrática Prueba:\",sklearn.metrics.mean_squared_error(test_prediction, test_target,squared=False))"
      ],
      "id": "588b3d36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn import tree\n",
        "\n",
        "listacaract=list(df1_Ori.columns.values)\n",
        "respuesta=listacaract.pop()\n",
        "text_representation = tree.export_text(decision_tree_Orig)\n",
        "print(text_representation)"
      ],
      "id": "56e5d58c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig = plt.figure(figsize=(25,20))\n",
        "_ = tree.plot_tree(decision_tree_Orig, \n",
        "                   feature_names=listacaract,  \n",
        "                   class_names=[respuesta],\n",
        "                   filled=True)"
      ],
      "id": "6a6682fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora miraremos las predicciones comparadas con los valores verdaderos, para ver más claro lo anterior.\n"
      ],
      "id": "8ec10689"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(train_val_prediction.size)\n",
        "print(train_val_target.size)\n",
        "\n",
        "print(test_prediction.size)\n",
        "print(test_target.size)"
      ],
      "id": "7bfc57d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indicetrian_val_test=df1_Ori.index\n",
        "print(indicetrian_val_test.size)  ###Tamaño del índice\n",
        "indicetrain_val=indicetrian_val_test[0:225]\n",
        "indicetest=indicetrian_val_test[225:280]"
      ],
      "id": "4f82acd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(indicetrain_val.size)\n",
        "print(indicetest.size)"
      ],
      "id": "005e5405",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "targetjoint=np.concatenate((train_val_target,test_target))\n",
        "predictionjoint=np.concatenate((train_val_prediction,test_prediction))\n",
        "print(targetjoint.size)\n",
        "print(predictionjoint.size)"
      ],
      "id": "bdfa5ddd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d = {'observado': targetjoint, 'Predicción': predictionjoint}\n",
        "ObsvsPred1=pd.DataFrame(data=d,index=indicetrian_val_test)\n",
        "ObsvsPred1.head(10)"
      ],
      "id": "3f888bb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#gráfico\n",
        "ax = ObsvsPred1['observado'].plot(marker=\"o\", figsize=(10, 6), linewidth=1, markersize=4)  # Ajusta el grosor de las líneas y puntos\n",
        "ObsvsPred1['Predicción'].plot(marker=\"o\", linewidth=1, markersize=2, ax=ax)  # Ajusta el grosor de las líneas y puntos\n",
        "# Agrega una línea vertical roja\n",
        "ax.axvline(x=indicetrian_val_test[223].date(), color='red', linewidth=0.5)  # Ajusta el grosor de la línea vertical\n",
        "# Muestra una leyenda\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "6791b5be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#metrica\n",
        "print(\"Raíz de la Pérdida cuadrática Entrenamiento:\",sklearn.metrics.mean_squared_error( ObsvsPred1['Predicción'][:223], ObsvsPred1['observado'][:223],squared=False))\n",
        "print(\"Raíz de la Pérdida cuadrática Prueba:\",sklearn.metrics.mean_squared_error(ObsvsPred1['Predicción'][223:], ObsvsPred1['observado'][223:],squared=False))"
      ],
      "id": "d43e6f45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Serie de Exportaciones sin Tendencia\n",
        "\n",
        "Implementaremos ahora el modelo de árboles sobre la serie sin tendencia, eliminada usando la estimación dada por medio del filtro de promedios móviles. Vamos a importar la bases de datos y a convertirlas en objetos de series de Tiempo. $\\{X_t\\}$\n"
      ],
      "id": "d8320d69"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lectura de la serie\n",
        "data2 = pd.ExcelFile('ExportacionesSinTendencia.xlsx')\n",
        "print(data2.sheet_names)\n",
        "# dataframe con los datos\n",
        "data2 = data2.parse('Sheet1')\n",
        "print(data2)\n",
        "print(type(data2))"
      ],
      "id": "c75950ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# tipo de datos\n",
        "print(data2.info())\n",
        "# nombre\n",
        "data2.columns = ['Fecha','Valor']\n",
        "print(data2.info())"
      ],
      "id": "ec057773",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# fecha\n",
        "data2['Fecha']=pd.to_datetime(data2['Fecha'])###Sólo es necesario si no tiene formato de fecha\n",
        "dlData = data2.set_index('Fecha')\n",
        "#dlData=dlData.asfreq('M')\n",
        "print(type(dlData))\n",
        "print(dlData)"
      ],
      "id": "790f77e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#mirando los datos\n",
        "#objeto ts\n",
        "exportaciones = dlData['Valor']\n",
        "print(type(exportaciones))\n",
        "plt.plot(exportaciones)"
      ],
      "id": "e2129c27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f'Numero de filas con valores faltantes: {data2.isnull().any(axis=1).mean()}')"
      ],
      "id": "4da90c26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dlData.shape"
      ],
      "id": "087d63ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PACF\n",
        "\n",
        "usaremos la funcion de autocorrealcion parcial para darnos una idea de cuantos rezagos usaremos en el modelo\n"
      ],
      "id": "dd78a68c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from matplotlib import pyplot\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "plot_pacf(exportaciones,lags=134,method='ywm',alpha=0.01)\n",
        "pyplot.show()"
      ],
      "id": "48cf3474",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "pacf =  sm.tsa.stattools.pacf(exportaciones, nlags=134,method='ywm')\n",
        "T = len(exportaciones)\n",
        "\n",
        "sig_test = lambda tau_h: np.abs(tau_h) > 2.58/np.sqrt(T)"
      ],
      "id": "b4bdc936",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pacf"
      ],
      "id": "96a395a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(len(pacf)):\n",
        "    if sig_test(pacf[i]) == False:\n",
        "        n_steps = i - 1\n",
        "        print('n_steps set to', n_steps)\n",
        "        break"
      ],
      "id": "954b8bbd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que con el **pacf** se nos recomienda usar un solo retardo, usaremos **1 retraso** para la serie sin Tendencia\n",
        "\n",
        "# Árboles de decisión\n",
        "\n",
        "### Creación de los rezagos\n",
        "\n",
        "Debido al análisis previo tomaremos los rezagos de 1 días atrás para poder predecir un paso adelante.\n"
      ],
      "id": "c9b3033f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas import DataFrame\n",
        "# reframe as supervised learning\n",
        "# lag observation (t-1) is the input variable and t is the output variable.\n",
        "df1 = DataFrame() # original\n",
        "print(df1)\n",
        "df2 = DataFrame() #diferenciada\n",
        "print(df2)"
      ],
      "id": "6b33e30b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# arreglo de datos para el arreglo de rezagos Serie Original\n",
        "indice = pd.date_range(start='2/1/2000', periods=281, freq='MS')\n",
        "print(indice)\n",
        "difDatadf = pd.DataFrame(data2['Valor'].values,index=indice)\n",
        "print(difDatadf)"
      ],
      "id": "c92f73f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Rezagos original\n",
        "for i in range(1,0,-1):\n",
        "    df2[['t-'+str(i)]] = difDatadf.shift(i)\n",
        "print(df2)"
      ],
      "id": "72352666",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create column t original\n",
        "df2['t'] = difDatadf.values\n",
        "print(df2.head(14))"
      ],
      "id": "90307292",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a new subsetted dataframe, removing Nans from first 3 rows original\n",
        "df2_dif = df2[1:]\n",
        "print(df2_dif)\n",
        "df2_dif.size"
      ],
      "id": "37d178e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split data Serie Original\n",
        "dif_Split = df2_dif.values\n",
        "# split into lagged variables and original time series\n",
        "X2 = dif_Split[:, 0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
        "y2 = dif_Split[:,-1]  # slice all rows and last column, essentially separating out 't' column\n",
        "print(X2)\n",
        "print('Respuestas \\n',y2)"
      ],
      "id": "3dc33fd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Árbol para Serie Sin Tendencia\n",
        "\n",
        "#### Entrenamiento, Validación y prueba\n"
      ],
      "id": "79225b07"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Y1 = y1\n",
        "print('Complete Observations for Target after Supervised configuration: %d' %len(Y1))\n",
        "traintarget_size = int(len(Y1) * 0.70) \n",
        "valtarget_size = int(len(Y1) * 0.10)+1# Set split\n",
        "testtarget_size = int(len(Y1) * 0.20)# Set split\n",
        "print(traintarget_size,valtarget_size,testtarget_size)\n",
        "print('Train + Validation + Test: %d' %(traintarget_size+valtarget_size+testtarget_size))"
      ],
      "id": "72c03530",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Target Train-Validation-Test split(70-10-20)\n",
        "train_target, val_target,test_target = Y1[0:traintarget_size], Y1[(traintarget_size):(traintarget_size+valtarget_size)],Y1[(traintarget_size+valtarget_size):len(Y1)]\n",
        "\n",
        "print('Observations for Target: %d' % (len(Y1)))\n",
        "print('Training Observations for Target: %d' % (len(train_target)))\n",
        "print('Validation Observations for Target: %d' % (len(val_target)))\n",
        "print('Test Observations for Target: %d' % (len(test_target)))"
      ],
      "id": "d83f35af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Features Train--Val-Test split\n",
        "\n",
        "trainfeature_size = int(len(X1) * 0.70)\n",
        "valfeature_size = int(len(X1) * 0.10)+1# Set split\n",
        "testfeature_size = int(len(X1) * 0.20)# Set split\n",
        "train_feature, val_feature,test_feature = X1[0:traintarget_size],X1[(traintarget_size):(traintarget_size+valtarget_size)] ,X1[(traintarget_size+valtarget_size):len(Y1)]\n",
        "\n",
        "print('Observations for Feature: %d' % (len(X1)))\n",
        "print('Training Observations for Feature: %d' % (len(train_feature)))\n",
        "print('Validation Observations for Feature: %d' % (len(val_feature)))\n",
        "print('Test Observations for Feature: %d' % (len(test_feature)))"
      ],
      "id": "94197609",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Árbol\n"
      ],
      "id": "08c0444f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decision Tree Regresion Model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Create a decision tree regression model with default arguments\n",
        "decision_tree_Orig = DecisionTreeRegressor()  # max-depth not set\n",
        "# The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "# Fit the model to the training features(covariables) and targets(respuestas)\n",
        "decision_tree_Orig.fit(train_feature, train_target)\n",
        "# Check the score on train and test\n",
        "print(\"Coeficiente R2 sobre el conjunto de entrenamiento:\",decision_tree_Orig.score(train_feature, train_target))\n",
        "print(\"Coeficiente R2 sobre el conjunto de Validación:\",decision_tree_Orig.score(val_feature,val_target))  # predictions are horrible if negative value, no relationship if 0\n",
        "print(\"el RECM sobre validación es:\",(((decision_tree_Orig.predict(val_feature)-val_target)**2).mean()) )"
      ],
      "id": "991b685c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que el R2 para los datos de validación es malo pues  es negativo, Se relizará un ajuste de la profundidad como hiperparametro para ver si mejora dicho valor\n"
      ],
      "id": "b5fbfa60"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find the best Max Depth\n",
        "\n",
        "# Loop through a few different max depths and check the performance\n",
        "# Try different max depths. We want to optimize our ML models to make the best predictions possible.\n",
        "# For regular decision trees, max_depth, which is a hyperparameter, limits the number of splits in a tree.\n",
        "# You can find the best value of max_depth based on the R-squared score of the model on the test set.\n",
        "\n",
        "for d in [2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15]:\n",
        "    # Create the tree and fit it\n",
        "    decision_tree_Orig = DecisionTreeRegressor(max_depth=d)\n",
        "    decision_tree_Orig.fit(train_feature, train_target)\n",
        "    \n",
        "    # Print out the scores on train and test\n",
        "    print('max_depth=', str(d))\n",
        "    print(\"Coeficiente R2 sobre el conjunto de entrenamiento:\",decision_tree_Orig.score(train_feature, train_target))\n",
        "    print(\"Coeficiente R2 sobre el conjunto de validación:\",decision_tree_Orig.score(val_feature, val_target), '\\n')  # You want the test score to be positive and high\n",
        "    print(\"el RECM sobre el conjunto de validación es:\",sklearn.metrics.mean_squared_error(decision_tree_Orig.predict(val_feature),val_target, squared=False), '\\n')"
      ],
      "id": "d13134bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note que los scores para el conjunto de validación son negativos para todas las profundidades evaluadas. Tomaremos el más cercano a cero que el el de la profundidad 2. Ahora uniremos validacion y entrenamiento para re para reestimar los parametros\n"
      ],
      "id": "1f735428"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(train_feature))\n",
        "print(type(val_feature))\n",
        "#######\n",
        "print(type(train_target))\n",
        "print(type(val_target))\n",
        "####\n",
        "print(train_feature.shape)\n",
        "print(val_feature.shape)\n",
        "#####\n",
        "####\n",
        "print(train_target.shape)\n",
        "print(val_target.shape)\n",
        "###Concatenate Validation and test\n",
        "train_val_feature=np.concatenate((train_feature,val_feature),axis=0)\n",
        "train_val_target=np.concatenate((train_target,val_target),axis=0)\n",
        "print(train_val_feature.shape)\n",
        "print(train_val_target.shape)"
      ],
      "id": "ef25d8d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use the best max_depth \n",
        "decision_tree_Orig = DecisionTreeRegressor(max_depth=2)  # fill in best max depth here\n",
        "decision_tree_Orig.fit(train_val_feature, train_val_target)\n",
        "\n",
        "# Predict values for train and test\n",
        "train_val_prediction = decision_tree_Orig.predict(train_val_feature)\n",
        "test_prediction = decision_tree_Orig.predict(test_feature)\n",
        "\n",
        "# Scatter the predictions vs actual values\n",
        "plt.scatter(train_val_prediction, train_val_target, label='train')  # blue\n",
        "plt.scatter(test_prediction, test_target, label='test')  # orange\n",
        "# Agrega títulos a los ejes\n",
        "plt.xlabel('Valores Predichos')  # Título para el eje x\n",
        "plt.ylabel('Valores Objetivo')  # Título para el eje y\n",
        "# Muestra una leyenda\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"Raíz de la Pérdida cuadrática Entrenamiento:\",sklearn.metrics.mean_squared_error( train_val_prediction, train_val_target,squared=False))\n",
        "\n",
        "print(\"Raíz de la Pérdida cuadrática Prueba:\",sklearn.metrics.mean_squared_error(test_prediction, test_target,squared=False))"
      ],
      "id": "0bb7cd29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn import tree\n",
        "\n",
        "listacaract=list(df1_Ori.columns.values)\n",
        "respuesta=listacaract.pop()\n",
        "text_representation = tree.export_text(decision_tree_Orig)\n",
        "print(text_representation)"
      ],
      "id": "8d2c58f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig = plt.figure(figsize=(25,20))\n",
        "_ = tree.plot_tree(decision_tree_Orig, \n",
        "                   feature_names=listacaract,  \n",
        "                   class_names=[respuesta],\n",
        "                   filled=True)"
      ],
      "id": "1b11d385",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora miraremos las predicciones comparadas con los valores verdaderos, para ver más claro lo anterior.\n"
      ],
      "id": "6911c61f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(train_val_prediction.size)\n",
        "print(train_val_target.size)\n",
        "\n",
        "print(test_prediction.size)\n",
        "print(test_target.size)"
      ],
      "id": "f42f53e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indicetrian_val_test=df1_Ori.index\n",
        "print(indicetrian_val_test.size)  ###Tamaño del índice\n",
        "indicetrain_val=indicetrian_val_test[0:215]\n",
        "indicetest=indicetrian_val_test[215:269]"
      ],
      "id": "a1a5428b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(indicetrain_val.size)\n",
        "print(indicetest.size)"
      ],
      "id": "2c10aa06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "targetjoint=np.concatenate((train_val_target,test_target))\n",
        "predictionjoint=np.concatenate((train_val_prediction,test_prediction))\n",
        "print(targetjoint.size)\n",
        "print(predictionjoint.size)"
      ],
      "id": "9ffcd7eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d = {'observado': targetjoint, 'Predicción': predictionjoint}\n",
        "ObsvsPred2=pd.DataFrame(data=d,index=indicetrian_val_test)\n",
        "ObsvsPred2.tail(54)"
      ],
      "id": "f2adc84d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#gráfico\n",
        "ax = ObsvsPred2['observado'].plot(marker=\"o\", figsize=(10, 6), linewidth=1, markersize=4)  # Ajusta el grosor de las líneas y puntos\n",
        "ObsvsPred2['Predicción'].plot(marker=\"o\", linewidth=1, markersize=2, ax=ax)  # Ajusta el grosor de las líneas y puntos\n",
        "# Agrega una línea vertical roja\n",
        "ax.axvline(x=indicetrian_val_test[223].date(), color='red', linewidth=0.5)  # Ajusta el grosor de la línea vertical\n",
        "# Muestra una leyenda\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "7ff97b68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora nos devolveremos a la escala original\n"
      ],
      "id": "1ad2df71"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#formando la de vuelta a la escala de los datos \n",
        "# datos transfromados para la diferencia\n",
        "# traer datos\n",
        "data_3 = pd.ExcelFile('datos/LExportaciones.xlsx')\n",
        "print(data_3.sheet_names)\n",
        "# dataframe con los datos\n",
        "data_3 = data_3.parse('Sheet 1')\n",
        "print(data_3)"
      ],
      "id": "9d325915",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#mirando los datos\n",
        "#objeto ts\n",
        "# nombre\n",
        "data_3.columns = ['Fecha','Valor']\n",
        "# fecha\n",
        "data_3['Fecha']=pd.to_datetime(data_3['Fecha'])###Sólo es necesario si no tiene formato de fecha\n",
        "LExportaciones = data_3.set_index('Fecha')\n",
        "#LExportaciones=LExportaciones.asfreq('M')\n",
        "print(type(LExportaciones))\n",
        "LExportaciones = LExportaciones.drop(['2017-01-01'])\n",
        "# para tipo de dato\n",
        "indiceL = LExportaciones.index\n",
        "d = {'observado L': LExportaciones['Valor']}\n",
        "ObsL=pd.DataFrame(data=d,index=indiceL)\n",
        "ObsL.head(10)"
      ],
      "id": "7bfd6983",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora devolvemos la diferenciación"
      ],
      "id": "232e810e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#necesitaremos arreglar los indices\n",
        "indices = ObsL['observado L'][6:275].index\n",
        "ObsvsPred2['Predicción'].index = indices\n",
        "# aqui devolvemos la diferenciación en escala log\n",
        "yhat_Dif = ObsvsPred2['Predicción'] + ObsL['observado L'][6:275]\n",
        "#yhat_Dif = yhat_Dif.drop('2000-07-01')\n",
        "print(yhat_Dif)"
      ],
      "id": "b4f2c935",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#volver a escala normal\n",
        "yhat = (((0.45)*yhat_Dif) + 1)**(1/0.45)\n",
        "print(yhat)"
      ],
      "id": "a73901f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = ObsvsPred1['observado'][6:275]\n",
        "#necesitaremos arreglar los indices\n",
        "indices = ObsL['observado L'][6:275].index\n",
        "y.index = indices\n",
        "print(y)\n",
        "#y = y.drop('2017-01-03')\n",
        "d = {'observado': y, 'Predicción': yhat}\n",
        "ObsvsPred3=pd.DataFrame(data=d,index=indices)\n",
        "ObsvsPred3.head(10)"
      ],
      "id": "f59ee321",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#gráfico\n",
        "ax = ObsvsPred3['observado'].plot(marker=\"o\", figsize=(10, 6), linewidth=2, markersize=4)  # Ajusta el grosor de las líneas y puntos\n",
        "ObsvsPred3['Predicción'].plot(marker=\"o\", linewidth=1, markersize=2, ax=ax)  # Ajusta el grosor de las líneas y puntos\n",
        "# Agrega una línea vertical roja\n",
        "ax.axvline(x=indicetrian_val_test[223].date(), color='red', linewidth=0.5)  # Ajusta el grosor de la línea vertical\n",
        "# Muestra una leyenda\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "0229ecf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#metrica\n",
        "print(\"Raíz de la Pérdida cuadrática Entrenamiento:\",sklearn.metrics.mean_squared_error( yhat[:222], y[:222],squared=False))\n",
        "print(\"Raíz de la Pérdida cuadrática Prueba:\",sklearn.metrics.mean_squared_error(yhat[222:], y[222:],squared=False))"
      ],
      "id": "d6c964e1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}